# 朴素贝叶斯法

## 笔记摘要
* 条件概率分布$P(X=x|Y=c_k)$有指数级数量的参数，其实际估计是不可行的

* 指数级数量的参数    $K\prod_{j=1}^nS_j$，实际估计不可行是实际上没有那么多样本
* 朴素贝叶斯法是基于**贝叶斯定理**与**特征条件独立假设**的分类方法
### 贝叶斯定理
$$P(B_i|A)=\frac{P(B_i)P(A|B_i)}{\sum _{j=1}^nP(B_j)P(A|B_j)}$$

### 条件独立假设

**independent and identically distributed** 

* 求$P(Y|X)$，其中$X\in\{X_1,X_2,\dots,X_n\}$，条件独立假设这里给定$Y$的情况下：

1. 每一个$X_i$和其他的每个$X_k$是条件独立的
1. 每一个$X_i$和其他的每个$X_k$的子集是条件独立的

* 条件独立性假设是:
$$
\begin{aligned}
P(X=x|Y=c_k)&=P(X^{(1)},\dots,X^{(n)}|Y=c_k)\\
&=\prod^n_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)
\end{aligned}
$$

* 条件独立假设等于是说用于分类的**特征**在**类确定**的条件下都是**条件独立**的

### 参数估计

#### 极大似然估计

> 为了估计状态变量的条件分布，利用贝叶斯法则，有
> $$
>    \underbrace{P(X|Y)}_{posterior}=\frac{\overbrace{P(Y|X)}^{likelihood}\overbrace{P(X)}^{prior}}{\underbrace{P(Y)}_{evidence}}=\frac{\overbrace{P(Y|X)}^{likelihood}\overbrace{P(X)}^{prior}}{\underbrace{\sum\limits_x P(Y|X)P(X)}_{evidence}}
> $$
> 其中$P(X|Y)$为给定$Y$下$X$的后验概率(Posterior)， $P(Y|X)$称为似然(Likelyhood)，$P(X)$称为先验(Prior)。
>

* 后验概率最大化的含义

  朴素贝叶斯法将实例分到**后验概率最大的类**中， 这等价于**期望风险最小化**。

* 后验是指观察到$Y$之后，对$X$的信念

#### 贝叶斯估计

* 对于$x$的某个特征的取值没有在先验中出现的情况 ，如果用极大似然估计就会出现所要估计的概率值为0的情况。这样会影响后验概率的计算结果，使分类产生偏差
* 但是出现这种情况的原因通常是因为数据集不能全覆盖样本空间，出现未知的情况处理的策略就是做平滑
$$
P_{\lambda}(X^{(j)}=a_{jl}|Y=c_k)=\frac{\sum\limits_{i=1}^NI(x_i^{j}=a_{jl},y_j=c_k)+\lambda}{\sum\limits_{i=1}^NI(y_j=c_k)+S_j\lambda}
$$

* 当$\lambda = 0$的时候，就是极大似然估计

* 当$\lambda=1$的时候，这个平滑方案叫做Laplace Smoothing。拉普拉斯平滑相当于给未知变量给定了先验概率


## 习题解答

* 4.1 用极大似然估计法推出朴素贝叶斯法中的概率估计公式(4.8)及公式 (4.9)
   *  由于朴素贝叶斯法假设Y是定义在输出空间上的随机变量，因此可以定义$P(Y=c_k)=p$,令$m=\sum _{i=1}^NI(y_i=c_k)$
   * 得出似然函数 $L(p)=p^m(1-p)^{N-m}$
   * 求导求最值：$mp^{m-1}(1-p)^{N-m}-(N-m)p^m(1-p)^{N-m-1}=0$
   * $p^{m-1}(1-p)^{N-m-1}(m-Np)=0$,易得$p=\frac mN$,即为公式（4.8）
   * 公式（4.9）的证明与公式（4.8）完全相同，定义$P(X^{(j)}=a_{jl}{\mid}Y=c_k)=p$，令$m=\sum_{i=1}^NI(y_i=c_k)$，$q=\sum_{i=1}^NI(x_i^{(j)}=a_{jl},y_i=c_k)$即可
* 4.2 用贝叶斯估计法推出朴素贝叶斯法中的慨率估计公式(4.10)及公式(4.11)
  *  贝叶斯估计和传统的极大似然估计的区别就是，参数值是固定的还是也当做随机变量。传统的极大似然估计，把参数$\theta$当做固定的一个值，不变的，只是目前还不知道，通过最大化$L$求出$\theta$；贝叶斯估计认为参数$\theta$也是随机变量，它也服从一个分布（β分布）
  * 设$P(Y=c_k)=p$,$m=\sum _{i=1}^NI(y_i=c_k)$,加入先验概率,认为是均匀的$p=\frac{1}{K}$，对照上题极大似然概率下的条件概率约束
  * 得到$\lambda (pK-1)+pN-m=0$,从而解出$P(Y=c_k)=\frac{m+\lambda}{N+K\lambda}$,即为公式（4.11）

